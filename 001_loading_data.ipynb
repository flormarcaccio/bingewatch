{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Netflix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_data(file_path):\n",
    "    f = open(file_path, 'rt')\n",
    "\n",
    "    data = f.readlines()\n",
    "\n",
    "    final_list = []\n",
    "    for i, line in enumerate(data):\n",
    "        if ':' in line:\n",
    "            current_movie_id = int(line[:-2])\n",
    "        elif ',' in line:\n",
    "            tmp = line[:-1].split(',')\n",
    "            final_list.append([current_movie_id, int(tmp[0]), int(tmp[1]), tmp[2]])\n",
    "    \n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading all four files with movie ratings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100480507\n",
      "0:30:29.084828\n"
     ]
    }
   ],
   "source": [
    "startTime = datetime.now()\n",
    "\n",
    "data = formatting_data('raw-data/combined_data_1.txt')\n",
    "data += formatting_data('raw-data/combined_data_2.txt')\n",
    "data += formatting_data('raw-data/combined_data_3.txt')\n",
    "data += formatting_data('raw-data/combined_data_4.txt')\n",
    "\n",
    "df_netflix = pd.DataFrame(data, columns = ['movie_id', 'user_id', 'rating', 'rating_date'])\n",
    "df_netflix.to_csv('netflix-prize-data/netflix_data.csv')\n",
    "\n",
    "print(len(data))\n",
    "del data\n",
    "print(datetime.now() - startTime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data info:\n",
      "Total number of ratings = 100480507\n",
      "Unique movies = 17770\n",
      "Unique users = 480189\n"
     ]
    }
   ],
   "source": [
    "print(\"Data info:\")\n",
    "print(\"Total number of ratings = \"+str(df_netflix.shape[0]))\n",
    "print(\"Unique movies = \"+str(len(np.unique(df_netflix[\"movie_id\"]))))\n",
    "print(\"Unique users = \"+str(len(np.unique(df_netflix[\"user_id\"]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated rows = 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Duplicated rows = \"+str(df_netflix.duplicated([\"movie_id\",\"user_id\", \"rating\"]).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN values = movie_id       0\n",
      "user_id        0\n",
      "rating         0\n",
      "rating_date    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of NaN values = \"+str(df_netflix.isnull().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating sparse matrix and calculating similarity between movies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_data = sparse.csr_matrix((df_netflix.rating, (df_netflix.user_id, df_netflix.movie_id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2649430, 17771)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = cosine_similarity(sparse_data.T, dense_output = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a dictionary with all the similar movies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_ids = np.unique(similarity.nonzero())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_movies_dict = dict()\n",
    "for movie in movie_ids:\n",
    "    rec_movies = np.argsort(-similarity[movie].toarray().ravel())[1:100]\n",
    "    similar_movies_dict[movie] = rec_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing dictionary in data folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/dict_recommendations.pkl', 'wb') as f:\n",
    "    pickle.dump(similar_movies_dict, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading raw data from https://datasets.imdbws.com/:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imdb_ratings = pd.read_csv('raw-data/title.ratings.tsv', sep = '\\t', na_values=['\\\\N'])\n",
    "df_imdb_titles = pd.read_csv('raw-data/title.basics.tsv', sep = '\\t', na_values=['\\\\N'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keeping only movies and series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imdb_titles = df_imdb_titles[df_imdb_titles.titleType.isin(['movie', 'tvSeries'])][['tconst', 'titleType', 'primaryTitle', 'startYear', 'genres']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging both sets, removing rows with no rating, genre or startYear, and adding weighted average:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imdb = df_imdb_titles.merge(df_imdb_ratings, how='left', left_on='tconst', right_on='tconst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imdb['titleType'] = df_imdb['titleType'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imdb = df_imdb.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imdb['weightedAverage'] = df_imdb['averageRating']*df_imdb['numVotes']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing final IMDb dataframe in the Data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imdb.to_csv('data/imdb_df.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing set of possible genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_raw = list(df_imdb['genres'].unique())\n",
    "genres = set([element for item in genres_raw for element in item.split(',')])\n",
    "with open('data/set_genres.pkl', 'wb') as f:\n",
    "    pickle.dump(genres, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILTER BY GENRE AND YEAR AND GET TOP 10\n",
    "#Loading IMDb dataframe\n",
    "#df_imdb = pd.read_csv('data/imdb_df.csv', sep = ',', header = 0)\n",
    "#Loading possible genres, not used in this cell\n",
    "#with open('data/set_genres.pkl', 'rb') as f:\n",
    "#    genres = pickle.load(f)\n",
    "\n",
    "#genre = 'Drama'\n",
    "#selected_year = 2020\n",
    "#selected_type = 'movie'\n",
    "#df_filtered = df_imdb[(df_imdb['genres'].str.contains(genre)) & (df_imdb['startYear'] == selected_year) & (df_imdb['titleType'] == selected_type)]\n",
    "#df_filtered.nlargest(10,'weightedAverage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HOW TO RECOMMEND TOP 10 MOVIES\n",
    "#Loading movie titles\n",
    "#movie_titles = pd.read_csv('data/movie_titles.csv', sep = ',', names = ['movie_id', 'year_released', 'title'], index_col = 'movie_id', encoding = 'iso8859_2')\n",
    "\n",
    "#Loading recommendation dictionary\n",
    "#dict_rec = {}\n",
    "#with open('data/dict_recommendations.pkl', 'rb') as f:\n",
    "#    dict_rec = pickle.load(f)\n",
    "\n",
    "#base_movie_id = 28\n",
    "\n",
    "#movie_titles.loc[dict_rec[base_movie_id][0][:10]] #I changed it so I access the first array for that key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some movie IDs to try the recommendation:  \n",
    "* 28: Lilo and Stitch  \n",
    "* 121: Beyonce  \n",
    "* 299: Bridget Jones's Diary  \n",
    "* 316: Futurama  \n",
    "* 409: Godzilla  \n",
    "* 607: Speed  \n",
    "* 621: Armageddon  \n",
    "* 1542: Sleepless in Seattle  \n",
    "* 2660: When Harry Met Sally  \n",
    "* 6287: Pretty Woman  \n",
    "* 6797: The Breakfast Club  \n",
    "* 11283: Forrest Gump  \n",
    "* 13763: Jerry Maguire  \n",
    "* 14928: Dead Poets Society  \n",
    "* 16879: Titanic  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
